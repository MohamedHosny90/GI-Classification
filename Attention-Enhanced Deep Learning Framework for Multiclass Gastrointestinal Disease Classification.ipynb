{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.layers import Layer, GlobalAveragePooling2D, Conv1D, Multiply, Reshape, Add, Conv2D, BatchNormalization, Activation, Dense, Dropout, Input, MaxPooling2D, Concatenate, AveragePooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.applications import MobileNet\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nimport keras\nimport tensorflow as tf\nimport os\nfrom tensorflow.keras.applications import ResNet50, DenseNet121\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB0\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Lambda, GlobalAveragePooling2D, Dense, Add, Input, BatchNormalization  # Add BatchNormalization here\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.applications import NASNetMobile\nfrom tensorflow.keras.applications import EfficientNetB7\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications import ResNet101\nfrom tensorflow.keras.applications import DenseNet201\nfrom tensorflow.keras.applications import NASNetLarge\nfrom tensorflow.keras.applications import EfficientNetV2B0\nfrom tensorflow.keras.applications import ConvNeXtBase\nimport tempfile \nimport shutil\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.model_selection import KFold\nimport numpy as np\n############################################Attention Mechanisms##########################\n# Custom Layers (SE Block)\n@keras.saving.register_keras_serializable()\nclass SEBlock(Layer):\n    def __init__(self, ratio=16, **kwargs):\n        super(SEBlock, self).__init__(**kwargs)\n        self.ratio = ratio\n\n    def build(self, input_shape):\n        self.num_channels = input_shape[-1]\n        self.squeeze = GlobalAveragePooling2D()\n        self.excitation = Dense(self.num_channels // self.ratio, activation='relu')\n        self.scale = Dense(self.num_channels, activation='sigmoid')\n\n    def call(self, inputs):\n        # Squeeze: Global Average Pooling\n        x = self.squeeze(inputs)\n        x = Reshape((1, 1, self.num_channels))(x)\n\n        # Excitation: Two fully connected layers\n        x = self.excitation(x)\n        x = self.scale(x)\n # Scale: Multiply the input with the excitation output\n        return Multiply()([inputs, x])\n############################################################################\n@keras.saving.register_keras_serializable()\nclass CBAM(Layer):\n    def __init__(self, ratio=16, **kwargs):\n        super(CBAM, self).__init__(**kwargs)\n        self.ratio = ratio\n\n    def build(self, input_shape):\n        self.channel_attention = ChannelAttention(ratio=self.ratio)\n        self.spatial_attention = SpatialAttention()\n\n    def call(self, inputs):\n        x = self.channel_attention(inputs)\n        x = self.spatial_attention(x)\n        return x\n\nclass ChannelAttention(Layer):\n    def __init__(self, ratio=16, **kwargs):\n        super(ChannelAttention, self).__init__(**kwargs)\n        self.ratio = ratio\n\n    def build(self, input_shape):\n        self.num_channels = input_shape[-1]\n        self.avg_pool = GlobalAveragePooling2D()\n        self.max_pool = GlobalMaxPooling2D()\n        self.fc1 = Dense(self.num_channels // self.ratio, activation='relu')\n        self.fc2 = Dense(self.num_channels, activation='sigmoid')\n\n    def call(self, inputs):\n        avg_out = self.fc2(self.fc1(self.avg_pool(inputs)))\n        max_out = self.fc2(self.fc1(self.max_pool(inputs)))\n        out = avg_out + max_out\n        return Multiply()([inputs, out])\n\nclass SpatialAttention(Layer):\n    def __init__(self, **kwargs):\n        super(SpatialAttention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.conv = Conv2D(1, 7, padding='same', activation='sigmoid')\n\n    def call(self, inputs):\n        avg_out = tf.reduce_mean(inputs, axis=3, keepdims=True)\n        max_out = tf.reduce_max(inputs, axis=3, keepdims=True)\n        out = tf.concat([avg_out, max_out], axis=3)\n        out = self.conv(out)\n        return Multiply()([inputs, out])\n############################################################################        \n@keras.saving.register_keras_serializable()\nclass SelfAttention(Layer):\n    def __init__(self, **kwargs):\n        super(SelfAttention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.num_channels = input_shape[-1]\n        self.query = Conv2D(self.num_channels // 8, 1, padding='same')\n        self.key = Conv2D(self.num_channels // 8, 1, padding='same')\n        self.value = Conv2D(self.num_channels, 1, padding='same')\n        self.gamma = self.add_weight(name='gamma', shape=[1], initializer='zeros')\n\n    def call(self, inputs):\n        batch_size, height, width, num_channels = tf.unstack(tf.shape(inputs))\n        query = self.query(inputs)\n        key = self.key(inputs)\n        value = self.value(inputs)\n\n        query = tf.reshape(query, [batch_size, height * width, num_channels // 8])\n        key = tf.reshape(key, [batch_size, height * width, num_channels // 8])\n        value = tf.reshape(value, [batch_size, height * width, num_channels])\n\n        attention = tf.matmul(query, key, transpose_b=True)\n        attention = tf.nn.softmax(attention, axis=-1)\n\n        out = tf.matmul(attention, value)\n        out = tf.reshape(out, [batch_size, height, width, num_channels])\n        out = self.gamma * out + inputs\n        return out\n#################################################################################\n@keras.saving.register_keras_serializable()\nclass ECANet(Layer):\n    def __init__(self, k_size=32, **kwargs):\n        super(ECANet, self).__init__(**kwargs)\n        self.k_size = k_size\n\n    def build(self, input_shape):\n        self.num_channels = input_shape[-1]\n        self.conv = Conv1D(1, kernel_size=self.k_size, padding='same', use_bias=False)\n\n    def call(self, inputs):\n        x = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n        x = tf.squeeze(x, axis=[1, 2])\n        x = self.conv(tf.expand_dims(x, axis=-1))\n        x = tf.squeeze(x, axis=-1)\n        x = tf.nn.sigmoid(x)\n        x = tf.expand_dims(tf.expand_dims(x, axis=1), axis=1)\n        return Multiply()([inputs, x])\n###############################################################################\n@keras.saving.register_keras_serializable()\nclass TripletAttention(Layer):\n    def __init__(self, **kwargs):\n        super(TripletAttention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.num_channels = input_shape[-1]\n        self.conv_h = Conv2D(self.num_channels, 1, padding='same', activation='sigmoid')\n        self.conv_w = Conv2D(self.num_channels, 1, padding='same', activation='sigmoid')\n        self.conv_c = Conv2D(self.num_channels, 1, padding='same', activation='sigmoid')\n\n    def call(self, inputs):\n        # Height attention\n        x_h = tf.reduce_mean(inputs, axis=2, keepdims=True)\n        x_h = self.conv_h(x_h)\n\n        # Width attention\n        x_w = tf.reduce_mean(inputs, axis=1, keepdims=True)\n        x_w = self.conv_w(x_w)\n\n        # Channel attention\n        x_c = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n        x_c = self.conv_c(x_c)\n\n        out = inputs * x_h * x_w * x_c\n        return out\n####################################################################################\n# Residual Block with Bottleneck\ndef residual_block(x, filters, strides=1):\n    shortcut = x\n    x = Conv2D(filters, (1, 1), strides=strides, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters * 4, (1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n\n    if strides != 1 or shortcut.shape[-1] != filters * 4:\n        shortcut = Conv2D(filters * 4, (1, 1), strides=strides, padding='same')(shortcut)\n        shortcut = BatchNormalization()(shortcut)\n\n    x = Add()([x, shortcut])\n    x = Activation('relu')(x)\n    return x\n##################################################################################\n# Global Context Block\ndef global_context_block(x):\n    gap = GlobalAveragePooling2D()(x)\n    gap = Reshape((1, 1, gap.shape[-1]))(gap)\n    gap = Conv2D(x.shape[-1], (1, 1), activation='sigmoid')(gap)\n    return Multiply()([x, gap])\n##################################################################################\n##################################################################################\ndef inception_module(x, filters):\n    \"\"\"Inception module with dimension reductions\"\"\"\n    # 1x1 branch\n    branch1x1 = Conv2D(filters[0], (1, 1), padding='same', activation='relu')(x)\n    \n    # 3x3 branch\n    branch3x3 = Conv2D(filters[1], (1, 1), padding='same', activation='relu')(x)\n    branch3x3 = Conv2D(filters[2], (3, 3), padding='same', activation='relu')(branch3x3)\n    \n    # 5x5 branch\n    branch5x5 = Conv2D(filters[3], (1, 1), padding='same', activation='relu')(x)\n    branch5x5 = Conv2D(filters[4], (5, 5), padding='same', activation='relu')(branch5x5)\n    \n    # Pooling branch\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = Conv2D(filters[5], (1, 1), padding='same', activation='relu')(branch_pool)\n    \n    # Concatenate all branches\n    return Concatenate()([branch1x1, branch3x3, branch5x5, branch_pool])\n####################################################################################\n# Custom Inception-Attention Block\ndef inception_mfr_attention_block(x, filters, attention_type='se'):\n    \"\"\"Inception -> Attention block\"\"\"\n    # First process through Inception module\n    x = inception_module(x, filters)\n    x = residual_block(x, filters=64, strides=2)\n    x = residual_block(x, filters=64, strides=1)\n    # Finally apply attention\n    if attention_type == 'se':\n       x = SEBlock()(x)\n       #x = ECANet()(x)\n       #x = CBAM()(x)\n       #x = SelfAttention()(x)\n       #x = TripletAttention()(x)\n    \n    return Activation('relu')(x)\n#######################################################################################\n# Define paths and classes\ndata_dir = '/kaggle/input/kvasirv2/KvasirV2'\nCLASSES = [\n    'dyed-lifted-polyps', 'dyed-resection-margins', 'esophagitis', \n    'normal-cecum', 'normal-pylorus', 'normal-z-line', 'polyps', 'ulcerative-colitis'\n]\n\n# First, collect all image paths and labels\nimage_paths = []\nlabels = []\n\nfor class_idx, class_name in enumerate(CLASSES):\n    class_path = os.path.join(data_dir, class_name)\n    for img_name in os.listdir(class_path):\n        image_paths.append(os.path.join(class_path, img_name))\n        labels.append(class_idx)\n\n# Convert to numpy arrays\nimage_paths = np.array(image_paths)\nlabels = np.array(labels)\n\nFolds = 3\n# Initialize KFold\nkfold = KFold(n_splits=Folds, shuffle=True, random_state=42)\n\n# Store histories for each fold\nfold_histories = []\nfold_metrics = []\n\nfor fold_idx, (train_idx, val_idx) in enumerate(kfold.split(image_paths)):\n    print(f\"\\nTraining fold {fold_idx + 1}/3\")\n    \n    # Create temporary directories for this fold\n    temp_dir = tempfile.mkdtemp()\n    train_folder = os.path.join(temp_dir, 'train')\n    val_folder = os.path.join(temp_dir, 'val')\n    os.makedirs(train_folder, exist_ok=True)\n    os.makedirs(val_folder, exist_ok=True)\n    \n    # Create class subdirectories\n    for class_name in CLASSES:\n        os.makedirs(os.path.join(train_folder, class_name), exist_ok=True)\n        os.makedirs(os.path.join(val_folder, class_name), exist_ok=True)\n    \n    # Copy images to respective folders\n    for idx in train_idx:\n        src = image_paths[idx]\n        class_name = CLASSES[labels[idx]]\n        dst = os.path.join(train_folder, class_name, os.path.basename(src))\n        shutil.copy(src, dst)\n    \n    for idx in val_idx:\n        src = image_paths[idx]\n        class_name = CLASSES[labels[idx]]\n        dst = os.path.join(val_folder, class_name, os.path.basename(src))\n        shutil.copy(src, dst)\n    \n    # Data generators\n    train_datagen = ImageDataGenerator(rescale=1./255)\n    \n    val_datagen = ImageDataGenerator(rescale=1./255)\n    \n    train_generator = train_datagen.flow_from_directory(\n        train_folder,\n        target_size=(224, 224),\n        batch_size=20,\n        color_mode='rgb',\n        shuffle=True,\n        class_mode='categorical'\n    )\n    \n    val_generator = val_datagen.flow_from_directory(\n        val_folder,\n        target_size=(224, 224),\n        batch_size=20,\n        color_mode='rgb',\n        shuffle=False,\n        class_mode='categorical'\n    )\n    \n    # Load DenseNet201 as a feature extractor\n    densenet201_base = DenseNet201(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n   \n    # Build model\n    x = densenet201_base.output\n    x = inception_mfr_attention_block(x, [32, 32, 64, 32, 64, 32], attention_type='se')\n    x = global_context_block(x)\n    x = GlobalAveragePooling2D()(x)\n    output = Dense(8, activation='softmax')(x)\n    model = Model(inputs=densenet201_base.input, outputs=output)\n    \n    # Compile\n    model.compile(optimizer=Adam(learning_rate=0.0001), \n                  loss='categorical_crossentropy', \n                  metrics=['accuracy'])\n    \n    # Callbacks\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n    model_checkpoint = ModelCheckpoint(f\"model_inception_mfr_attention_fold{fold_idx}.keras\", \n                                     save_best_only=True, \n                                     monitor='val_accuracy', mode = 'max')\n    \n    # Train\n    history = model.fit(\n        train_generator,\n        epochs=20,\n        validation_data=val_generator,\n        callbacks=[reduce_lr, model_checkpoint]\n    )\n    \n    # Save history and metrics\n    fold_histories.append(history)\n    fold_metrics.append(model.evaluate(val_generator))\n    \n    # Clean up temporary files\n    shutil.rmtree(temp_dir)\n\n# Print cross-validation results\nprint(\"\\nCross-validation results:\")\nfor i, (loss, acc) in enumerate(fold_metrics):\n    print(f\"Fold {i+1}: Loss = {loss:.4f}, Accuracy = {acc:.4f}\")\n\nmean_loss = np.mean([m[0] for m in fold_metrics])\nmean_acc = np.mean([m[1] for m in fold_metrics])\nprint(f\"\\nMean across folds: Loss = {mean_loss:.4f}, Accuracy = {mean_acc:.4f}\")\n###########################################################################################\n# Initialize variables to store metrics across folds\nall_reports = []\nall_confusion_matrices = []\nall_metrics = []\n\n# Function to evaluate model and plot confusion matrix\ndef evaluate_model(model, generator, fold_idx):\n    # Get true labels and predictions\n    y_true = generator.classes\n    y_pred = model.predict(generator)\n    y_pred_classes = np.argmax(y_pred, axis=1)\n    \n    # Classification report\n    class_names = list(generator.class_indices.keys())\n    report = classification_report(y_true, y_pred_classes, target_names=class_names, output_dict=True)\n    \n    # Calculate additional metrics\n    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_classes, average=None)\n    support = np.bincount(y_true)\n    \n    # Calculate specificity for each class\n    cm = confusion_matrix(y_true, y_pred_classes)\n    specificity = []\n    for i in range(len(class_names)):\n        tn = np.sum(np.delete(np.delete(cm, i, axis=0), i, axis=1))\n        fp = np.sum(cm[:, i]) - cm[i, i]\n        specificity.append(tn / (tn + fp))\n    \n    # Add to fold metrics\n    fold_metrics = {\n        'accuracy': report['accuracy'],\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1,\n        'specificity': specificity,\n        'support': support,\n        'confusion_matrix': cm\n    }\n    \n    return fold_metrics, report, cm\n\n\n# Process each fold\nfor fold_idx in range(Folds):\n    print(f\"\\nEvaluating Fold {fold_idx + 1}\")\n    \n    # Load the saved model for this fold\n    model = load_model(f\"model_inception_mfr_attention_fold{fold_idx}.keras\", compile=False)\n    model.compile(optimizer=Adam(learning_rate=0.0001), \n                  loss='categorical_crossentropy', \n                  metrics=['accuracy'])\n    \n    # Recreate validation data for this fold\n    temp_dir = tempfile.mkdtemp()\n    val_folder = os.path.join(temp_dir, 'val')\n    os.makedirs(val_folder, exist_ok=True)\n    \n    for class_name in CLASSES:\n        os.makedirs(os.path.join(val_folder, class_name), exist_ok=True)\n    \n    # Get the original fold indices\n    folds = list(kfold.split(image_paths))\n    _, val_idx = folds[fold_idx]\n    \n    # Copy validation images\n    for idx in val_idx:\n        src = image_paths[idx]\n        class_name = CLASSES[labels[idx]]\n        dst = os.path.join(val_folder, class_name, os.path.basename(src))\n        shutil.copy(src, dst)\n    \n    # Create validation generator\n    val_datagen = ImageDataGenerator(rescale=1./255)\n    val_generator = val_datagen.flow_from_directory(\n        val_folder,\n        target_size=(224, 224),\n        batch_size=20,\n        color_mode='rgb',\n        shuffle=False,\n        class_mode='categorical'\n    )\n    \n    # Evaluate the model\n    fold_metrics, report, cm = evaluate_model(model, val_generator, fold_idx)\n    all_reports.append(report)\n    all_confusion_matrices.append(cm)\n    all_metrics.append(fold_metrics)\n    \n    # Plot confusion matrix\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=CLASSES, \n                yticklabels=CLASSES)\n    plt.title(f'Confusion Matrix - Fold {fold_idx + 1}')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.xticks(rotation=45)\n    plt.yticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig(f'confusion_matrix_fold_{fold_idx+1}.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    # Print metrics for this fold\n    print(f\"\\nMetrics for Fold {fold_idx + 1}:\")\n    print(f\"Accuracy: {fold_metrics['accuracy']:.4f}\")\n    print(\"Class-wise metrics:\")\n    for i, class_name in enumerate(CLASSES):\n        print(f\"{class_name}:\")\n        print(f\"  Precision: {fold_metrics['precision'][i]:.4f}\")\n        print(f\"  Recall: {fold_metrics['recall'][i]:.4f}\")\n        print(f\"  F1-score: {fold_metrics['f1_score'][i]:.4f}\")\n        print(f\"  Specificity: {fold_metrics['specificity'][i]:.4f}\")\n    \n    # Clean up\n    shutil.rmtree(temp_dir)\n\n# Calculate average metrics across folds\navg_metrics = {\n    'accuracy': np.mean([m['accuracy'] for m in all_metrics]),\n    'precision': np.mean([m['precision'] for m in all_metrics], axis=0),\n    'recall': np.mean([m['recall'] for m in all_metrics], axis=0),\n    'f1_score': np.mean([m['f1_score'] for m in all_metrics], axis=0),\n    'specificity': np.mean([m['specificity'] for m in all_metrics], axis=0),\n    'support': all_metrics[0]['support']  # Support is the same across folds\n}\n\n# Calculate macro-averaged metrics\nmacro_precision = np.mean(avg_metrics['precision'])\nmacro_recall = np.mean(avg_metrics['recall'])\nmacro_f1 = np.mean(avg_metrics['f1_score'])\n\n# Save all metrics to Excel\nwith pd.ExcelWriter('cross_validation_metrics.xlsx') as writer:\n    # Save each fold's metrics\n    for fold_idx in range(Folds):\n        fold_df = pd.DataFrame({\n            'Class': CLASSES,\n            'Precision': all_metrics[fold_idx]['precision'],\n            'Recall': all_metrics[fold_idx]['recall'],\n            'F1-score': all_metrics[fold_idx]['f1_score'],\n            'Specificity': all_metrics[fold_idx]['specificity'],\n            'Support': all_metrics[fold_idx]['support']\n        })\n        fold_df.to_excel(writer, sheet_name=f'Fold_{fold_idx+1}', index=False)\n    \n    # Save average metrics\n    avg_df = pd.DataFrame({\n        'Class': CLASSES,\n        'Avg_Precision': avg_metrics['precision'],\n        'Avg_Recall': avg_metrics['recall'],\n        'Avg_F1-score': avg_metrics['f1_score'],\n        'Avg_Specificity': avg_metrics['specificity'],\n        'Support': avg_metrics['support']\n    })\n    avg_df.to_excel(writer, sheet_name='Average_Metrics', index=False)\n    \n    # Add overall metrics\n    overall_df = pd.DataFrame({\n        'Metric': ['Accuracy', 'Precision (Macro)', 'Recall (Macro)', 'F1-score (Macro)'],\n        'Average': [avg_metrics['accuracy'], macro_precision, macro_recall, macro_f1]\n    })\n    overall_df.to_excel(writer, sheet_name='Overall', index=False)\n\n# Print average metrics\nprint(\"\\nAverage Metrics Across All Folds:\")\nprint(f\"Accuracy: {avg_metrics['accuracy']:.4f}\")\nprint(f\"Macro Precision: {macro_precision:.4f}\")\nprint(f\"Macro Recall: {macro_recall:.4f}\")\nprint(f\"Macro F1-score: {macro_f1:.4f}\")\nprint(\"Class-wise averages:\")\nfor i, class_name in enumerate(CLASSES):\n    print(f\"{class_name}:\")\n    print(f\"  Precision: {avg_metrics['precision'][i]:.4f}\")\n    print(f\"  Recall: {avg_metrics['recall'][i]:.4f}\")\n    print(f\"  F1-score: {avg_metrics['f1_score'][i]:.4f}\")\n    print(f\"  Specificity: {avg_metrics['specificity'][i]:.4f}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}